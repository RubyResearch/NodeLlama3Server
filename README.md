# Node Llama3 Server

This is a backend server for running Llama3 model locally with chatCompletion and embedding functions.


## Run

[https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/tree/main]
You need to download the necessary gguf model file and copy and paste it into the ./src/services/models folder.
Then

```sh
npm install
npm run start
```